{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /s/chopin/l/grad/fahadktk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from fastprogress import progress_bar\n",
    "\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetIMDB(Dataset):\n",
    "    \"\"\"\n",
    "    max_len: Maximum review length (in number of words) to use for padding\n",
    "    min_len: Minimum review length (in number of words) to keep\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, file_path, transform=\"embd\", embedding=\"default\", min_len = 10, max_len = 300, remove_stopWords = True):\n",
    "        self.transform = transform\n",
    "        self.max_len = max_len\n",
    "        self.data = feather.read_dataframe(file_path)\n",
    "        self.data['review'] = self.data.Text.apply(lambda x: x.replace('<br />',''))\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        if remove_stopWords:\n",
    "            self.data['review'] = self.data.review.apply(lambda x: ' '.join([c for c in x.split() if c not in stop_words]))\n",
    "        self.data['review'] = self.data.review.apply(lambda x: ''.join([c for c in x if c not in punctuation]))\n",
    "        self.data['textLen'] = self.data.review.apply(lambda x: len([c for c in x.split()]))\n",
    "        self.data = self.data[self.data['textLen'].isin([i for i in range(min_len,max_len)])].reset_index() #pick \n",
    "        \n",
    "        if embedding == \"default\":\n",
    "            self.word_to_ix = {}\n",
    "            for review in self.data['review']:\n",
    "                for word in review.split():\n",
    "                    if word not in self.word_to_ix:\n",
    "                        self.word_to_ix[word] = len(self.word_to_ix)\n",
    "            #print(word_to_ix)\n",
    "            self.tag_to_ix = {\"1\": 1, \"0\": 0} #not useful right now\n",
    "            #tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def pad_data(self, s):\n",
    "        padded = np.zeros((self.max_len,), dtype=np.int64)\n",
    "        if len(s) > self.max_len: padded[:] = s[:self.max_len]\n",
    "        else: padded[:len(s)] = s\n",
    "        return padded\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        review = self.data['review'][index]\n",
    "        label = self.data['label'][index]\n",
    "       \n",
    "        \n",
    "        if self.transform is not None:\n",
    "            idxs = [self.word_to_ix[w] for w in review.split()]\n",
    "            lenReview = min(len(idxs),self.max_len)\n",
    "            idxs = self.pad_data(idxs)\n",
    "            \n",
    "            review = torch.tensor(idxs, dtype=torch.long) #creating tensor here is slow\n",
    "        label = torch.tensor(label,dtype=torch.long)\n",
    "            \n",
    "        return review, label, lenReview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetIMDBversion2(Dataset):\n",
    "    \"\"\"\n",
    "    max_len: Maximum review length (in number of words) to use for padding\n",
    "    min_len: Minimum review length (in number of words) to keep\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, file_path, transform=\"embd\", embedding=\"default\", min_len = 10, max_len = 300, remove_stopWords = True, device=None, feather=True):\n",
    "        self.transform = transform\n",
    "        self.max_len = max_len\n",
    "        #self.data = feather.read_dataframe(file_path)\n",
    "        self.data = pd.read_csv(file_path) if feather==False else feather.read_dataframe(file_path)\n",
    "        self.data['review'] = self.data.review.apply(lambda x: x.replace('<br />',''))\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        if remove_stopWords:\n",
    "            self.data['review'] = self.data.review.apply(lambda x: ' '.join([c for c in x.split() if c not in stop_words]))\n",
    "        self.data['review'] = self.data.review.apply(lambda x: ''.join([c for c in x if c not in punctuation]))\n",
    "        self.data['textLen'] = self.data.review.apply(lambda x: len([c for c in x.split()]))\n",
    "        self.data = self.data[self.data['textLen'].isin([i for i in range(min_len,max_len)])].reset_index() #pick \n",
    "        \n",
    "        if embedding == \"default\":\n",
    "            self.word_to_ix = {}\n",
    "            for review in self.data['review']:\n",
    "                for word in review.split():\n",
    "                    if word not in self.word_to_ix:\n",
    "                        self.word_to_ix[word] = (len(self.word_to_ix)) + 1# avoid starting from 0\n",
    "            #print(word_to_ix)\n",
    "            self.tag_to_ix = {\"1\": 1, \"0\": 0} #not useful right now\n",
    "            #tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
    "        \n",
    "        self.idx_list = []\n",
    "        self.lenReview_list = []\n",
    "        self.label_list = []\n",
    "        \n",
    "        print(\"Generating Data Tensors...\")\n",
    "        for i in progress_bar(range(0,self.data.shape[0])):\n",
    "            review = self.data['review'][i]\n",
    "            label = self.data['label'][i] \n",
    "            \n",
    "            if self.transform is not None:\n",
    "                idxs = [self.word_to_ix[w] for w in review.split()]\n",
    "                lenReview = min(len(idxs),self.max_len)\n",
    "                idxs = self.pad_data(idxs)\n",
    "                \n",
    "                review = torch.tensor(idxs, dtype=torch.long) #creating tensor here is slow\n",
    "                self.idx_list.append(review)\n",
    "            label = torch.tensor(label,dtype=torch.long)\n",
    "            self.label_list.append(label)\n",
    "            \n",
    "            lenReivew = torch.tensor(lenReview, dtype=torch.long)\n",
    "            self.lenReview_list.append(lenReview)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def pad_data(self, s):\n",
    "        padded = np.zeros((self.max_len,), dtype=np.int64)\n",
    "        if len(s) > self.max_len: padded[:] = s[:self.max_len]\n",
    "        else: padded[:len(s)] = s\n",
    "        return padded\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.idx_list[index], self.label_list[index], self.lenReview_list[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "valid_split = .2\n",
    "shuffle_data = True\n",
    "rand_seed= 100\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Data Tensors...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='39252' class='' max='39252', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [39252/39252 00:04<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset = DatasetIMDB('data/classification/imdb_train.feather',remove_stopWords=False)\n",
    "#testdataset = DatasetIMDB('data/classification/imdb_test.feather',remove_stopWords=False)\n",
    "#dataset = DatasetIMDBversion2('data/classification/imdb_train.feather',remove_stopWords=False,device=device)\n",
    "dataset = DatasetIMDBversion2('IMDB_Dataset_v2.csv', remove_stopWords=False, device=device, feather=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(valid_split * dataset_size))\n",
    "if shuffle_data:\n",
    "    np.random.seed(rand_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indx, val_indx = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indx)\n",
    "valid_sampler = SubsetRandomSampler(val_indx)\n",
    "#test_sampler = SubsetRandomSampler([i for i in range(0,2000)]+[j for j in range(15200,17200)])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler, drop_last=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler, drop_last=True)\n",
    "#validation_loader = torch.utils.data.DataLoader(testdataset, batch_size=batch_size, #can't use different dataset since the token IDs will change?\n",
    "#                                          sampler=test_sampler)\n",
    "#test_loader = torch.utils.data.DataLoader(testdataset, batch_size=batch_size,\n",
    "#                                          sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31402, 7850)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_indx),len(val_indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage Example:\n",
    "#num_epochs = 10\n",
    "#for epoch in range(num_epochs):\n",
    "#    # Train:   \n",
    "#    for batch_index, (faces, labels) in enumerate(train_loader):\n",
    "#        # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172727"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMiMDB(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMiMDB, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx = 0) #try with padding_idx = 0\n",
    "        #print (self.word_em)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        #self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.lstm = nn.GRU(embedding_dim, hidden_dim,batch_first=True)\n",
    "        \n",
    "        #self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # The linear layer that maps from hidden state space to target space\n",
    "        self.target = nn.Linear(hidden_dim, tagset_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, review, lengths):\n",
    "        #pdb.set_trace()\n",
    "\n",
    "        self.embs = self.word_embeddings(review)\n",
    "        self.embspack = pack_padded_sequence(self.embs, lengths,batch_first=True) # unpad enforce_sorted=False\n",
    "        lstm_out, self.h = self.lstm(self.embspack) # gru returns hidden state of all timesteps as well as hidden state at last timestep\n",
    "        #lstm_out, lengths = pad_packed_sequence(lstm_out) # pad the sequence to the max length in the batch (not needed here)\n",
    "        \n",
    "        #outp = self.target(self.h[0]) #for LSTM\n",
    "        outp = self.target(self.h) # For GRU #vs self.h[-1]? self.h shape[1,batch_size,num_hidden] and self.h[-1] shape[batch_size,num_hidden] (basically the same thing?)\n",
    "        \n",
    "        return outp\n",
    "        #return F.softmax(outp, dim=-1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = np.round(preds)\n",
    "    correct = (rounded_preds == y)#.float() #convert into float for division \n",
    "    acc = 5.0#float(correct).sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_auc = 0\n",
    "    epoch_f1 = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    #for i in progress_bar(range(0,len(iterator))):\n",
    "    for batch in progress_bar(iterator):\n",
    "        #batch = iterator[i]\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, labels, lengths = batch\n",
    "        lengths_Argsorted = lengths.argsort(descending=True)\n",
    "        lengths = lengths[lengths_Argsorted]\n",
    "        text = text[lengths_Argsorted]\n",
    "        labels = labels[lengths_Argsorted]\n",
    "        text = text.to(device)\n",
    "        labels = labels.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        \n",
    "        predictions = model(text,lengths).squeeze()\n",
    "        \n",
    "        #print(predictions[:,1])\n",
    "        #print(predictions.shape,labels.shape)\n",
    "        \n",
    "        loss = criterion(predictions, labels)\n",
    "        \n",
    "        labels = labels.cpu().detach().numpy()\n",
    "        softmax = torch.nn.Softmax(dim=1)\n",
    "        predictions = softmax(predictions).cpu().detach().numpy()\n",
    "        \n",
    "        acc = binary_accuracy(predictions[:,-1], labels)\n",
    "        #print(np.asarray(labels),predictions[:,1])\n",
    "        \n",
    "        fpr, tpr, thresholds = metrics.roc_curve(np.asarray(labels), predictions[:,-1])\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        f1 = metrics.f1_score(labels, np.round(predictions[:,-1]))\n",
    "      \n",
    "        #print(\"Loss and Accuracy: \",loss,acc)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item() #0 for checking speed\n",
    "        epoch_acc += acc#.item()\n",
    "        epoch_auc += auc\n",
    "        epoch_f1 += f1\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_auc/len(iterator), epoch_f1/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_auc = 0\n",
    "    epoch_f1 = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in progress_bar(iterator):\n",
    "\n",
    "            text, labels, lengths = batch\n",
    "            lengths_Argsorted = lengths.argsort(descending=True)\n",
    "            lengths = lengths[lengths_Argsorted]\n",
    "            text = text[lengths_Argsorted]\n",
    "            labels = labels[lengths_Argsorted]\n",
    "            text = text.to(device)\n",
    "            labels = labels.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            \n",
    "            predictions = model(text,lengths).squeeze()\n",
    "            \n",
    "            loss = criterion(predictions, labels)\n",
    "            \n",
    "            softmax = torch.nn.Softmax(dim=1)\n",
    "            predictions = softmax(predictions).cpu().detach().numpy()\n",
    "            labels = labels.cpu().detach().numpy()\n",
    "            \n",
    "            acc = binary_accuracy(predictions[:,-1], labels)\n",
    "            \n",
    "            fpr, tpr, thresholds = metrics.roc_curve(np.asarray(labels), predictions[:,-1])\n",
    "            auc = metrics.auc(fpr, tpr)\n",
    "            f1 = metrics.f1_score(labels, np.round(predictions[:,-1]))\n",
    "\n",
    "            epoch_loss += loss.item() #0 for checking speed\n",
    "            epoch_acc += acc#.item()\n",
    "            epoch_auc += auc\n",
    "            epoch_f1 += f1\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_auc/len(iterator), epoch_f1/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMiMDB(EMBEDDING_DIM, HIDDEN_DIM, len(dataset.word_to_ix)+1, len(dataset.tag_to_ix)).to(device)\n",
    "loss_function = nn.CrossEntropyLoss(reduction='mean')   #nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters())#, weight_decay = 0.01)   #optim.Adam(model.parameters()) #optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "#model = model.to(device)\n",
    "#loss_function = loss_function.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMiMDB(\n",
       "  (word_embeddings): Embedding(172728, 100, padding_idx=0)\n",
       "  (lstm): GRU(100, 50, batch_first=True)\n",
       "  (target): Linear(in_features=50, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='490' class='' max='490', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [490/490 00:11<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='122' class='' max='122', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [122/122 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.627 | Train Acc: 500.00 | Train Auc: 0.69 | Train F1-score: 0.63\n",
      "\t Val. Loss: 0.654 |  Val. Acc: 500.00 |  Val. Auc: 0.67 | Valid F1-score: 0.63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='490' class='' max='490', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [490/490 00:11<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='122' class='' max='122', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [122/122 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.585 | Train Acc: 500.00 | Train Auc: 0.75 | Train F1-score: 0.68\n",
      "\t Val. Loss: 0.493 |  Val. Acc: 500.00 |  Val. Auc: 0.85 | Valid F1-score: 0.78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='490' class='' max='490', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [490/490 00:11<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='122' class='' max='122', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [122/122 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.418 | Train Acc: 500.00 | Train Auc: 0.89 | Train F1-score: 0.81\n",
      "\t Val. Loss: 0.407 |  Val. Acc: 500.00 |  Val. Auc: 0.90 | Valid F1-score: 0.81\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='490' class='' max='490', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [490/490 00:11<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='122' class='' max='122', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [122/122 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.287 | Train Acc: 500.00 | Train Auc: 0.95 | Train F1-score: 0.88\n",
      "\t Val. Loss: 0.349 |  Val. Acc: 500.00 |  Val. Auc: 0.93 | Valid F1-score: 0.86\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='490' class='' max='490', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [490/490 00:11<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='122' class='' max='122', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [122/122 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.185 | Train Acc: 500.00 | Train Auc: 0.98 | Train F1-score: 0.93\n",
      "\t Val. Loss: 0.337 |  Val. Acc: 500.00 |  Val. Auc: 0.94 | Valid F1-score: 0.86\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='490' class='' max='490', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [490/490 00:11<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='122' class='' max='122', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [122/122 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.119 | Train Acc: 500.00 | Train Auc: 0.99 | Train F1-score: 0.96\n",
      "\t Val. Loss: 0.374 |  Val. Acc: 500.00 |  Val. Auc: 0.94 | Valid F1-score: 0.87\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='490' class='' max='490', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [490/490 00:11<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='122' class='' max='122', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [122/122 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.072 | Train Acc: 500.00 | Train Auc: 1.00 | Train F1-score: 0.98\n",
      "\t Val. Loss: 0.433 |  Val. Acc: 500.00 |  Val. Auc: 0.94 | Valid F1-score: 0.87\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='490' class='' max='490', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [490/490 00:11<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='122' class='' max='122', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [122/122 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Epoch Time: 0m 12s\n",
      "\tTrain Loss: 0.047 | Train Acc: 500.00 | Train Auc: 1.00 | Train F1-score: 0.99\n",
      "\t Val. Loss: 0.462 |  Val. Acc: 500.00 |  Val. Auc: 0.94 | Valid F1-score: 0.87\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='490' class='' max='490', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [490/490 00:11<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='122', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-cc2d91177740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-5d2a1eb2e7b4>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, iterator, criterion, device)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/s/jawar/h/nobackup/fahad/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-c2fb7f89794f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, review, lengths)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membspack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# unpad enforce_sorted=False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membspack\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# gru returns hidden state of all timesteps as well as hidden state at last timestep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#lstm_out, lengths = pad_packed_sequence(lstm_out) # pad the sequence to the max length in the batch (not needed here)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/s/jawar/h/nobackup/fahad/miniconda3/lib/python3.7/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train(model,train_loader,optimizer,loss_function)\n",
    "N_EPOCHS = 15\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc, train_auc, train_f1 = train(model, train_loader, optimizer, loss_function, device)\n",
    "    valid_loss, valid_acc, valid_auc, valid_f1 = evaluate(model, validation_loader, loss_function, device)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'lstmIMDB_model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f} | Train Auc: {train_auc:.2f} | Train F1-score: {train_f1:.2f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f} |  Val. Auc: {valid_auc:.2f} | Valid F1-score: {valid_f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embs = model.embs[:,0,:].clone().data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 100)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(test_embs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in validation_loader:\n",
    "        text, labels, lengths = batch\n",
    "        lengths_Argsorted = lengths.argsort(descending=True)\n",
    "        lengths = lengths[lengths_Argsorted]\n",
    "        text = text[lengths_Argsorted]\n",
    "        labels = labels[lengths_Argsorted]\n",
    "        predictions = model(text.t(),lengths)\n",
    "        #softmax = torch.sigmoid()\n",
    "        preds = torch.sigmoid(predictions)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([56, 300, 100])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 100])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embs[0,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29350,    40, 21080,   964,    13,   966,   899,    13,   157,  5434,\n",
       "        11703, 12574,  7147,   207,   381,   805, 12301,  1540,  9337,  9338,\n",
       "         1839,   207, 12857,     9,  4375, 29351,    68,  6681,  8158,  4911,\n",
       "        21080,   132,  6681,  8158, 20177, 15647, 29352,  2896,    55,  9853,\n",
       "          567,  5522, 21080,    82,   112,  9339, 29353,    12, 10759,  1012,\n",
       "          132,  6263,   132,     9,   976,  1186,   558,   259,   585,  5380,\n",
       "        29354,   132,  3704, 13961,   183, 29355, 29356,    19,   813,  1073,\n",
       "         1494,   259,  2004,    82,  2166,  7885,   132,  5815,   155,    82,\n",
       "           13,  5447,   907,    15,  1064,     3,   294,  3666,    12,    13,\n",
       "        10614,  6838,  1281, 21080, 28998,  6681,  8158,    55,  2593,  9064,\n",
       "           19, 12304,    74,    12,  3980,   183, 24202,  1885,   236,    13,\n",
       "         5447,    76,    82, 10295,   294,  4679,   132,  9220,   259,  1670,\n",
       "           82,   294, 11141,  1839,   294,  7476,   132,   921,   259,   929,\n",
       "           82,  1584, 13526,  1839,   294,  5418,  6681,  8158,   585,   227,\n",
       "            9,    92,  2678,   567,  1917,   259,  3388,   932,    12, 29357,\n",
       "           13, 13704,    19,    13,  3988,   259, 29358,  5793,    55,    13,\n",
       "        10690,    19,    13,   244,   622,    12, 29357,    13, 29359,    19,\n",
       "           13,  3236,   283,  3093, 13529,    82,     9, 29360,  2398,  1620,\n",
       "         4371,     0,  1938,    19,    13, 18325,   132,     0, 29361,  1277,\n",
       "          784,   260,    13,  5447,   294,  9817,    12, 21080,   159,   183,\n",
       "         9729,    49,  3266, 17151,   159,    13,  4600,   294,   228,    12,\n",
       "         6681,  8158,    55,  1426,   249,    13,    19,    13,  5990,   224,\n",
       "         7274,   482,  3676,   783,    68,  2004,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 10\n",
    "final_review = []\n",
    "for ix in text[index].clone().data.cpu().numpy():\n",
    "    for key in dataset.word_to_ix:\n",
    "        if dataset.word_to_ix[key] == ix:\n",
    "            final_review.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor([0.1950, 0.8014]))"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 10\n",
    "labels[index],preds[0][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Overshadowed by Braveheart released the same year the two costume dramas beg comparison I admit my bias against Mel Gibson yet I maintain a rational preference for Rob Roy Both Braveheart and Rob Roy compellingly depict Scots history in bloody romantic fashion Braveheart is an epic paean to individual honor and courage and a fine revenge fantasy Its also melodramatic anachronistic and maudlin Note its cornball usage of slow motion filming Its violence is both ugly and glorious It is the latter quality which makes it more appealing to the adolescent mindset While Braveheart surpasses Rob Roy in sheer levels of carnage not to mention its indulgent running time the latter film is ultimately more mature and satisfying Its action is more understated yet more surprising and clever Its sex is less showy yet more erotic Rob Roy also has a better realized romantic interest Its dialog attempts to approximate the poetry of the period Its rotted teeth in the mouths of the actors attempt to approximate the dentistry of the era And Tim Roth is a superlative villain Also recommended The Last of the Mohicans and The Patriot You may find the latter more akin to Braveheart with its emphasis on blood lust with the former more similar to Rob Roy in tone All the of the aforementioned movies merit their R ratings for violence The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The The'"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(final_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embs = model.embs[index,:,:].clone().data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "test_embs_mean = np.mean(test_embs,axis=1)\n",
    "test_embs_mean_args = np.argsort(test_embs_mean)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['of', 'of', 'of', 'of', 'of', 'of', 'of', 'its', 'its', 'its', 'a',\n",
       "       'a', 'a', 'a', 'which', 'revenge', 'approximate', 'approximate',\n",
       "       'appealing', 'costume', 'Last', 'honor', 'villain', 'bloody',\n",
       "       'maudlin', 'two', 'interest', 'anachronistic', 'Rob', 'Rob', 'Rob',\n",
       "       'Rob', 'Rob', 'both', 'their', 'fine', 'it', 'poetry', 'history',\n",
       "       'less', 'carnage', 'filming', 'find', 'yet', 'yet', 'yet', 'and',\n",
       "       'and', 'and', 'and', 'and', 'and', 'and', 'and', 'You', 'mention',\n",
       "       'sheer', 'comparison', 'violence', 'violence', 'slow', 'released',\n",
       "       'indulgent', 'rotted', 'an', 'former', 'film', 'tone',\n",
       "       'melodramatic', 'admit', 'more', 'more', 'more', 'more', 'more',\n",
       "       'more', 'more', 'Scots', 'not', 'may', 'against', 'sex', 'I', 'I',\n",
       "       'compellingly', 'fantasy', 'realized', 'lust', 'merit', 'usage',\n",
       "       'Both', 'showy', 'understated', 'bias', 'fashion', 'with', 'with',\n",
       "       'And', 'time', 'dramas', 'quality', 'action', 'R', 'dialog', 'The',\n",
       "       'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The',\n",
       "       'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The',\n",
       "       'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The',\n",
       "       'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The',\n",
       "       'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The',\n",
       "       'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The',\n",
       "       'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The',\n",
       "       'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The', 'The',\n",
       "       'The', 'The', 'The', 'year', 'Its', 'Its', 'Its', 'Its', 'Its',\n",
       "       'Its', 'courage', 'by', 'mouths', 'satisfying', 'emphasis',\n",
       "       'ratings', 'makes', 'paean', 'erotic', 'Also', 'preference',\n",
       "       'recommended', 'in', 'in', 'in', 'in', 'same', 'Roy', 'Roy', 'Roy',\n",
       "       'Roy', 'Roy', 'better', 'levels', 'on', 'attempts', 'ugly', 'for',\n",
       "       'for', 'dentistry', 'running', 'era', 'beg', 'teeth', 'depict',\n",
       "       'my', 'Tim', 'Gibson', 'Mel', 'period', 'All', 'While', 'also',\n",
       "       'also', 'actors', 'Braveheart', 'Braveheart', 'Braveheart',\n",
       "       'Braveheart', 'Braveheart', 'superlative', 'ultimately', 'blood',\n",
       "       'is', 'is', 'is', 'is', 'is', 'is', 'is', 'motion', 'similar',\n",
       "       'Patriot', 'adolescent', 'Note', 'movies', 'latter', 'latter',\n",
       "       'latter', 'It', 'maintain', 'glorious', 'surprising', 'clever',\n",
       "       'has', 'romantic', 'romantic', 'akin', 'epic', 'cornball',\n",
       "       'aforementioned', 'rational', 'Mohicans', 'attempt', 'Roth',\n",
       "       'individual', 'mindset', 'Overshadowed', 'surpasses', 'mature',\n",
       "       'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the',\n",
       "       'the', 'the', 'the', 'the', 'the', 'the', 'the', 'to', 'to', 'to',\n",
       "       'to', 'to', 'to', 'to'], dtype='<U14')"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(final_review)[test_embs_mean_args]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import shap.explainers.deep.deep_pytorch as shapdpt\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 300])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Embedding in module torch.nn.modules.sparse:\n",
      "\n",
      "class Embedding(torch.nn.modules.module.Module)\n",
      " |  A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
      " |  \n",
      " |  This module is often used to store word embeddings and retrieve them using indices.\n",
      " |  The input to the module is a list of indices, and the output is the corresponding\n",
      " |  word embeddings.\n",
      " |  \n",
      " |  Args:\n",
      " |      num_embeddings (int): size of the dictionary of embeddings\n",
      " |      embedding_dim (int): the size of each embedding vector\n",
      " |      padding_idx (int, optional): If given, pads the output with the embedding vector at :attr:`padding_idx`\n",
      " |                                       (initialized to zeros) whenever it encounters the index.\n",
      " |      max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`\n",
      " |                                  is renormalized to have norm :attr:`max_norm`.\n",
      " |      norm_type (float, optional): The p of the p-norm to compute for the :attr:`max_norm` option. Default ``2``.\n",
      " |      scale_grad_by_freq (boolean, optional): If given, this will scale gradients by the inverse of frequency of\n",
      " |                                              the words in the mini-batch. Default ``False``.\n",
      " |      sparse (bool, optional): If ``True``, gradient w.r.t. :attr:`weight` matrix will be a sparse tensor.\n",
      " |                               See Notes for more details regarding sparse gradients.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      weight (Tensor): the learnable weights of the module of shape (num_embeddings, embedding_dim)\n",
      " |                       initialized from :math:`\\mathcal{N}(0, 1)`\n",
      " |  \n",
      " |  Shape:\n",
      " |      - Input: :math:`(*)`, LongTensor of arbitrary shape containing the indices to extract\n",
      " |      - Output: :math:`(*, H)`, where `*` is the input shape and :math:`H=\\text{embedding\\_dim}`\n",
      " |  \n",
      " |  .. note::\n",
      " |      Keep in mind that only a limited number of optimizers support\n",
      " |      sparse gradients: currently it's :class:`optim.SGD` (`CUDA` and `CPU`),\n",
      " |      :class:`optim.SparseAdam` (`CUDA` and `CPU`) and :class:`optim.Adagrad` (`CPU`)\n",
      " |  \n",
      " |  .. note::\n",
      " |      With :attr:`padding_idx` set, the embedding vector at\n",
      " |      :attr:`padding_idx` is initialized to all zeros. However, note that this\n",
      " |      vector can be modified afterwards, e.g., using a customized\n",
      " |      initialization method, and thus changing the vector used to pad the\n",
      " |      output. The gradient for this vector from :class:`~torch.nn.Embedding`\n",
      " |      is always zero.\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> # an Embedding module containing 10 tensors of size 3\n",
      " |      >>> embedding = nn.Embedding(10, 3)\n",
      " |      >>> # a batch of 2 samples of 4 indices each\n",
      " |      >>> input = torch.LongTensor([[1,2,4,5],[4,3,2,9]])\n",
      " |      >>> embedding(input)\n",
      " |      tensor([[[-0.0251, -1.6902,  0.7172],\n",
      " |               [-0.6431,  0.0748,  0.6969],\n",
      " |               [ 1.4970,  1.3448, -0.9685],\n",
      " |               [-0.3677, -2.7265, -0.1685]],\n",
      " |  \n",
      " |              [[ 1.4970,  1.3448, -0.9685],\n",
      " |               [ 0.4362, -0.4004,  0.9400],\n",
      " |               [-0.6431,  0.0748,  0.6969],\n",
      " |               [ 0.9124, -2.3616,  1.1151]]])\n",
      " |  \n",
      " |  \n",
      " |      >>> # example with padding_idx\n",
      " |      >>> embedding = nn.Embedding(10, 3, padding_idx=0)\n",
      " |      >>> input = torch.LongTensor([[0,2,0,5]])\n",
      " |      >>> embedding(input)\n",
      " |      tensor([[[ 0.0000,  0.0000,  0.0000],\n",
      " |               [ 0.1535, -2.0309,  0.9315],\n",
      " |               [ 0.0000,  0.0000,  0.0000],\n",
      " |               [-0.1655,  0.9897,  0.0635]]])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Embedding\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  extra_repr(self)\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should reimplement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  forward(self, input)\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  reset_parameters(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_pretrained(embeddings, freeze=True, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False) from builtins.type\n",
      " |      Creates Embedding instance from given 2-dimensional FloatTensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          embeddings (Tensor): FloatTensor containing weights for the Embedding.\n",
      " |              First dimension is being passed to Embedding as ``num_embeddings``, second as ``embedding_dim``.\n",
      " |          freeze (boolean, optional): If ``True``, the tensor does not get updated in the learning process.\n",
      " |              Equivalent to ``embedding.weight.requires_grad = False``. Default: ``True``\n",
      " |          padding_idx (int, optional): See module initialization documentation.\n",
      " |          max_norm (float, optional): See module initialization documentation.\n",
      " |          norm_type (float, optional): See module initialization documentation. Default ``2``.\n",
      " |          scale_grad_by_freq (boolean, optional): See module initialization documentation. Default ``False``.\n",
      " |          sparse (bool, optional): See module initialization documentation.\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          >>> # FloatTensor containing pretrained weights\n",
      " |          >>> weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]])\n",
      " |          >>> embedding = nn.Embedding.from_pretrained(weight)\n",
      " |          >>> # Get embeddings for index 1\n",
      " |          >>> input = torch.LongTensor([1])\n",
      " |          >>> embedding(input)\n",
      " |          tensor([[ 4.0000,  5.1000,  6.3000]])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __constants__ = ['num_embeddings', 'embedding_dim', 'padding_idx', 'ma...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__(self, *input, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      __dir__() -> list\n",
      " |      default dir() implementation\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name, module)\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self, fn)\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`torch-nn-init`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.data.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  buffers(self, recurse=True)\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf.data), buf.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self)\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self)\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self, device=None)\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self)\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self)\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |  \n",
      " |  float(self)\n",
      " |      Casts all floating point parameters and buffers to float datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  half(self)\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict, strict=True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |  \n",
      " |  modules(self)\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix='', recurse=True)\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self)\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo=None, prefix='')\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix='', recurse=True)\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse=True)\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param.data), param.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook)\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> Tensor or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n",
      " |      module has multiple inputs or outputs. The hook should not modify its\n",
      " |      arguments, but it can optionally return a new gradient with respect to\n",
      " |      input that will be used in place of :attr:`grad_input` in subsequent\n",
      " |      computations.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |      \n",
      " |      .. warning ::\n",
      " |      \n",
      " |          The current implementation will not have the presented behavior\n",
      " |          for complex :class:`Module` that perform many operations.\n",
      " |          In some failure cases, :attr:`grad_input` and :attr:`grad_output` will only\n",
      " |          contain the gradients for a subset of the inputs and outputs.\n",
      " |          For such :class:`Module`, you should use :func:`torch.Tensor.register_hook`\n",
      " |          directly on a specific input or output to get the required gradients.\n",
      " |  \n",
      " |  register_buffer(self, name, tensor)\n",
      " |      Adds a persistent buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the persistent state.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor): buffer to be registered.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook)\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None\n",
      " |      \n",
      " |      The hook should not modify the input or output.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook)\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None\n",
      " |      \n",
      " |      The hook should not modify the input.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_parameter(self, name, param)\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter): parameter to be added to the module.\n",
      " |  \n",
      " |  share_memory(self)\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point desired :attr:`dtype` s. In addition, this method will\n",
      " |      only cast the floating point parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point type of\n",
      " |              the floating point parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |  \n",
      " |  train(self, mode=True)\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self, dst_type)\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self)\n",
      " |      Sets gradients of all model parameters to zero.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn.LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "only Tensors of floating point dtype can require gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-345-873a9b148636>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeepExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/shap/explainers/deep/__init__.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mwere\u001b[0m \u001b[0mchosen\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m\"top\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranked_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_rank_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/shap/explainers/deep/deep_pytorch.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;31m# run attribution computation graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0mfeature_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output_ranks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                 \u001b[0msample_phis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoint_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                 \u001b[0;31m# assign the attributions to the right part of the output arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/shap/explainers/deep/deep_pytorch.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, idx, inputs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mselected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/shap/explainers/deep/deep_pytorch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mselected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: only Tensors of floating point dtype can require gradients"
     ]
    }
   ],
   "source": [
    "background = text[:60]\n",
    "bglengths = lengths[:60]\n",
    "test_reviews = text[60:64]\n",
    "test_lengths = lengths[60:64]\n",
    "\n",
    "data = [background, bglengths]\n",
    "data_test = [test_reviews,test_lengths]\n",
    "#pdb.set_trace()\n",
    "e = shap.DeepExplainer(model, data)\n",
    "shap_values = e.shap_values(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(data) == list, \"Expected a list of model inputs!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DeepExplainer in module shap.explainers.deep:\n",
      "\n",
      "class DeepExplainer(shap.explainers.explainer.Explainer)\n",
      " |  Meant to approximate SHAP values for deep learning models.\n",
      " |  \n",
      " |  This is an enhanced version of the DeepLIFT algorithm (Deep SHAP) where, similar to Kernel SHAP, we\n",
      " |  approximate the conditional expectations of SHAP values using a selection of background samples.\n",
      " |  Lundberg and Lee, NIPS 2017 showed that the per node attribution rules in DeepLIFT (Shrikumar,\n",
      " |  Greenside, and Kundaje, arXiv 2017) can be chosen to approximate Shapley values. By integrating\n",
      " |  over many backgound samples DeepExplainer estimates approximate SHAP values such that they sum\n",
      " |  up to the difference between the expected model output on the passed background samples and the\n",
      " |  current model output (f(x) - E[f(x)]).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DeepExplainer\n",
      " |      shap.explainers.explainer.Explainer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, model, data, session=None, learning_phase_flags=None)\n",
      " |      An explainer object for a differentiable model using a given background dataset.\n",
      " |      \n",
      " |      Note that the complexity of the method scales linearly with the number of background data\n",
      " |      samples. Passing the entire training dataset as `data` will give very accurate expected\n",
      " |      values, but be unreasonably expensive. The variance of the expectation estimates scale by\n",
      " |      roughly 1/sqrt(N) for N background data samples. So 100 samples will give a good estimate,\n",
      " |      and 1000 samples a very good estimate of the expected values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      model : if framework == 'tensorflow', (input : [tf.Operation], output : tf.Operation)\n",
      " |           A pair of TensorFlow operations (or a list and an op) that specifies the input and\n",
      " |          output of the model to be explained. Note that SHAP values are specific to a single\n",
      " |          output value, so the output tf.Operation should be a single dimensional output (,1).\n",
      " |      \n",
      " |          if framework == 'pytorch', an nn.Module object (model), or a tuple (model, layer),\n",
      " |              where both are nn.Module objects\n",
      " |          The model is an nn.Module object which takes as input a tensor (or list of tensors) of\n",
      " |          shape data, and returns a single dimensional output.\n",
      " |          If the input is a tuple, the returned shap values will be for the input of the\n",
      " |          layer argument. layer must be a layer in the model, i.e. model.conv2\n",
      " |      \n",
      " |      data :\n",
      " |          if framework == 'tensorflow': [numpy.array] or [pandas.DataFrame]\n",
      " |          if framework == 'pytorch': [torch.tensor]\n",
      " |          The background dataset to use for integrating out features. DeepExplainer integrates\n",
      " |          over these samples. The data passed here must match the input operations given in the\n",
      " |          first argument. Note that since these samples are integrated over for each sample you\n",
      " |          should only something like 100 or 1000 random background samples, not the whole training\n",
      " |          dataset.\n",
      " |      \n",
      " |      if framework == 'tensorflow':\n",
      " |      \n",
      " |      session : None or tensorflow.Session\n",
      " |          The TensorFlow session that has the model we are explaining. If None is passed then\n",
      " |          we do our best to find the right session, first looking for a keras session, then\n",
      " |          falling back to the default TensorFlow session.\n",
      " |      \n",
      " |      learning_phase_flags : None or list of tensors\n",
      " |          If you have your own custom learning phase flags pass them here. When explaining a prediction\n",
      " |          we need to ensure we are not in training mode, since this changes the behavior of ops like\n",
      " |          batch norm or dropout. If None is passed then we look for tensors in the graph that look like\n",
      " |          learning phase flags (this works for Keras models). Note that we assume all the flags should\n",
      " |          have a value of False during predictions (and hence explanations).\n",
      " |  \n",
      " |  shap_values(self, X, ranked_outputs=None, output_rank_order='max')\n",
      " |      Return approximate SHAP values for the model applied to the data given by X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : list,\n",
      " |          if framework == 'tensorflow': numpy.array, or pandas.DataFrame\n",
      " |          if framework == 'pytorch': torch.tensor\n",
      " |          A tensor (or list of tensors) of samples (where X.shape[0] == # samples) on which to\n",
      " |          explain the model's output.\n",
      " |      \n",
      " |      ranked_outputs : None or int\n",
      " |          If ranked_outputs is None then we explain all the outputs in a multi-output model. If\n",
      " |          ranked_outputs is a positive integer then we only explain that many of the top model\n",
      " |          outputs (where \"top\" is determined by output_rank_order). Note that this causes a pair\n",
      " |          of values to be returned (shap_values, indexes), where shap_values is a list of numpy\n",
      " |          arrays for each of the output ranks, and indexes is a matrix that indicates for each sample\n",
      " |          which output indexes were choses as \"top\".\n",
      " |      \n",
      " |      output_rank_order : \"max\", \"min\", or \"max_abs\"\n",
      " |          How to order the model outputs when using ranked_outputs, either by maximum, minimum, or\n",
      " |          maximum absolute value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      For a models with a single output this returns a tensor of SHAP values with the same shape\n",
      " |      as X. For a model with multiple outputs this returns a list of SHAP value tensors, each of\n",
      " |      which are the same shape as X. If ranked_outputs is None then this list of tensors matches\n",
      " |      the number of model outputs. If ranked_outputs is a positive integer a pair is returned\n",
      " |      (shap_values, indexes), where shap_values is a list of tensors with a length of\n",
      " |      ranked_outputs, and indexes is a matrix that indicates for each sample which output indexes\n",
      " |      were chosen as \"top\".\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from shap.explainers.explainer.Explainer:\n",
      " |  \n",
      " |  attributions(self, X)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from shap.explainers.explainer.Explainer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(shap.DeepExplainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model(*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  207,   207,   478,  ...,   916,   207, 24632],\n",
      "        [  763,   256,    61,  ...,   664,    58,   322],\n",
      "        [ 7826,  4476,   619,  ...,   266,  1060,   185],\n",
      "        ...,\n",
      "        [ 3960,     0,     0,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]]) tensor([298, 297, 291, 283, 270, 262, 260, 235, 235, 234, 226, 225, 224, 223,\n",
      "        222, 220, 217, 212, 203, 201, 196, 195, 191, 189, 188, 185, 184, 182,\n",
      "        174, 174, 172, 160, 158, 157, 156, 155, 152, 144, 143, 143, 137, 137,\n",
      "        135, 135, 131, 127, 127, 125, 123, 121, 119, 118, 117, 114, 112, 112,\n",
      "        109, 109, 109,  94])\n"
     ]
    }
   ],
   "source": [
    "print(*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='61' class='' max='61', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [61/61 01:39<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_loss, valid_acc, valid_auc, valid_f1 = evaluate(model, validation_loader, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics.precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3656083770462724, 0.840273711525026, 0.927367345262119, 0.8520957465360808)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_loss,valid_acc,valid_auc, valid_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in validation_loader:\n",
    "    text, labels, lengths = batch\n",
    "            \n",
    "    predictions = model(text.t(),lengths).squeeze()\n",
    "            \n",
    "    loss = loss_function(predictions, labels)\n",
    "            \n",
    "    acc = binary_accuracy(predictions[:,1], labels)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdataset = DatasetIMDB('data/classification/imdb_test.feather',remove_stopWords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19771"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampler = SubsetRandomSampler([i for i in range(0,3000)]+[j for j in range(14200,17200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(testdataset, batch_size=batch_size,sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate(model, test_loader, loss_function) #won't work since tokens are different in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(110300, 100, padding_idx=0)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 207,  256, 4476,  ...,    0,    0,    0],\n",
       "        [ 358,  143,   19,  ...,    0,    0,    0],\n",
       "        [4777,  908,   55,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [3466,    9,  167,  ...,    0,    0,    0],\n",
       "        [ 207, 3797, 3199,  ...,    0,    0,    0],\n",
       "        [   0,  938,  178,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][batch[-1].argsort(descending=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 20, 44, 57, 49, 61, 32, 46, 42, 39,  8, 54, 52, 31, 26, 35, 62, 43,\n",
       "        28, 29, 25, 63, 58, 15, 59, 37, 19,  5, 30, 36, 47, 50,  9,  3, 45, 40,\n",
       "        12,  1, 48,  4, 14, 38, 13, 55, 53, 51, 22, 17, 34, 56,  7, 21, 33, 60,\n",
       "        24, 27,  2,  6, 23, 11, 10, 16,  0, 41])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[-1].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  207,   256,  4476,    12,   261,   115,    76,   111,   120,    91,\n",
       "           19,     3,    82, 94457,    35,   223,  1612,   108,    19,    13,\n",
       "         7377,    82,  8306,  2576,     0,  2862,  3457, 11003,   663,    45,\n",
       "          254,    31,   482,  2064, 20818,    82, 18314, 14401,    19,    13,\n",
       "           51,    55,    13,  6427,  3427,  1508,  4034, 27020,   805,  2629,\n",
       "        22162,   805, 94458, 22162,   805, 46960, 18274,   364,   207, 10705,\n",
       "          730,    12,   538,    13, 94459, 10718,  4159,  1211, 51278,  4236,\n",
       "          132,    74,   260,  2243, 10358,    55,  1075,   358,   575, 72445,\n",
       "         2230,   450,   132,     9,  3310, 13515, 55839, 36291,     4,   346,\n",
       "        94460,  7047,   228,    71,  2118,  5104,   792,   228,  1820,  5348,\n",
       "        94461,     0, 25081, 11638,    55,    13, 17427, 18500,   227,     9,\n",
       "          874,   228,  1845,    12,   318,    55, 51278,   132,  2166,  1353,\n",
       "         1661,     9,   912,    19, 94462, 94463,    19,   115,  1171,    12,\n",
       "          168,    55,  3225,  5912,    12,    13,  3325,  5674,    35,  3975,\n",
       "           46,    13,   402, 37860,    31,    13,  3489,   227,    62,     9,\n",
       "        19473, 58666,   102,   179,  2101,  2010,    15,   585, 67578,   482,\n",
       "          148, 42896,    19,  1353,    55,    13,  3735,    31,   385,   727,\n",
       "           91, 29780,    19,   313,   223,   159,   108,  2082, 94464,    12,\n",
       "         1075,   132, 94465,  3870,   810,  2297,    12,  1104,    13,   453,\n",
       "         9803,    49,   183,   613,   132,  1566,  4786,  2940, 21130,   132,\n",
       "         4605,  2482,    55,  1470,  1399,   133,   545,   429,   122,    58,\n",
       "           13,   464, 19112,    68,   332, 36757,  2398,    82,   256, 27319,\n",
       "          132,  5398,  4159,   132,  1017,     9,  2777,    12,   538,  7373,\n",
       "           19,    13,  2187,    19,    13,    76,  1171, 94466,  2105,    19,\n",
       "           13,  7028,   546,   261,  3783,    35,    13, 94467,    76,   218,\n",
       "        11252,   159,     9,  1459,  2974, 11898,  1883,  6675,    13,   402,\n",
       "           19,   115,  4034,   429,   178,  5417,    31,  3975,   179,    77,\n",
       "           58,    91,  1917,    55, 94468,   296,   533,  2256,   121,   810,\n",
       "           12,   123,    31,  1428,  1650,   293,   450,    49,    13,   671,\n",
       "          373,    82,  1415,   963,    19,   482,  7084,     0,     0,     0])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][41]#tokenize from 0 or 1? if we use 0 padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 32])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].t().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sigmoid in module torch.nn.functional:\n",
      "\n",
      "sigmoid(input)\n",
      "    sigmoid(input) -> Tensor\n",
      "    \n",
      "    Applies the element-wise function :math:`\\text{Sigmoid}(x) = \\frac{1}{1 + \\exp(-x)}`\n",
      "    \n",
      "    See :class:`~torch.nn.Sigmoid` for more details.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(F.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0], dtype=int32)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='100' class='' max='100', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [100/100 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in progress_bar(range(100)):\n",
    "    ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(nn.LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
