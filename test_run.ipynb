{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /s/chopin/l/grad/fahadktk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from fastprogress import progress_bar\n",
    "from nltk.corpus import stopwords\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# The raw cells are from https://nbviewer.jupyter.org/github/radoslawkrolikowski/sentiment-analysis-pytorch/blob/master/1_data_processing.ipynb\n",
    "def load_data(path, file_list, dataset, encoding='utf8'):\n",
    "    \"\"\"Read set of files from given directory and save returned lines to list.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Absolute or relative path to given file (or set of files).\n",
    "    file_list: list\n",
    "        List of files names to read.\n",
    "    dataset: list\n",
    "        List that stores read lines.\n",
    "    encoding: str, optional (default='utf8')\n",
    "        File encoding.\n",
    "        \n",
    "    \"\"\"\n",
    "    for file in file_list:\n",
    "        with open(os.path.join(path, file), 'r', encoding=encoding) as text:\n",
    "            dataset.append(text.read())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Path to dataset location\n",
    "path = 'aclImdb/'\n",
    "\n",
    "# Create lists that will contain read lines\n",
    "train_pos, train_neg, test_pos, test_neg = [], [], [], []\n",
    "\n",
    "# Create a dictionary of paths and lists that store lines (key: value = path: list)\n",
    "sets_dict = {'train/pos/': train_pos, 'train/neg/': train_neg,\n",
    "             'test/pos/': test_pos, 'test/neg/': test_neg}\n",
    "\n",
    "# Load the data\n",
    "for dataset in sets_dict:\n",
    "        file_list = [f for f in os.listdir(os.path.join(path, dataset)) if f.endswith('.txt')]\n",
    "        load_data(os.path.join(path, dataset), file_list, sets_dict[dataset])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Concatenate training and testing examples into one dataset\n",
    "dataset = pd.concat([pd.DataFrame({'review': train_pos, 'label':1}),\n",
    "                     pd.DataFrame({'review': test_pos, 'label':1}),\n",
    "                     pd.DataFrame({'review': train_neg, 'label':0}),\n",
    "                     pd.DataFrame({'review': test_neg, 'label':0})],\n",
    "                     axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset.to_csv('IMDB_Dataset_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, file_path, min_len=10, max_len=300, embedding='default', remove_stopWords=True, device=None):\n",
    "        self.max_len = max_len\n",
    "        self.min_len = min_len\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        #self.data['label'] = self.data['sentiment'].apply(lambda x: 1 if x=='positive' else 0)\n",
    "        self.data['review'] = self.data.review.apply(lambda x: x.replace('<br />', ''))\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        if remove_stopWords:\n",
    "            self.data['review'] = self.data.review.apply(lambda x: ' '.join([c for c in x.split() if c not in stop_words]))\n",
    "        self.data['review'] = self.data.review.apply(lambda x: ''.join([c for c in x if c not in punctuation]))\n",
    "        self.data['reviewLen'] = self.data.review.apply(lambda x: len([c for c in x.split()]))\n",
    "        self.data = self.data[self.data['reviewLen'].isin([i for i in range(self.min_len, self.max_len)])].reset_index(drop=True)    \n",
    "        if embedding=='default':\n",
    "            self.word_to_ix = {}\n",
    "            for review in self.data['review']:\n",
    "                for word in review.split():\n",
    "                    if word not in self.word_to_ix:\n",
    "                        self.word_to_ix[word] = len(self.word_to_ix)+1 #0 is for paddings\n",
    "        self.tag_to_ix = {\"1\":1, \"0\":0}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def pad_data(self, s):\n",
    "        padded = np.zeros((self.max_len,),dtype=np.int64)\n",
    "        if len(s) > self.max_len: padded[:] = s[:self.max_len]\n",
    "        else: padded[:len(s)] = s\n",
    "        return padded\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        review = self.data['review'][index]\n",
    "        label = self.data['label'][index]\n",
    "        idxs = [self.word_to_ix[w] for w in review.split()]\n",
    "        lenReview = self.data['reviewLen'][index]#min(len(idxs), self.max_len)\n",
    "        idxs = self.pad_data(idxs)\n",
    "        review = torch.tensor(idxs, dtype=torch.long)\n",
    "        #label = self.tag_to_ix[label]\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return review, label, lenReview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDatasetv2(Dataset):\n",
    "    def __init__(self, file_path, min_len=10, max_len=300, embedding='default', remove_stopWords=True, device=None):\n",
    "        self.max_len = max_len\n",
    "        self.min_len = min_len\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        #self.data['label'] = self.data['sentiment'].apply(lambda x: \"1\" if x=='positive' else \"0\")\n",
    "        self.data['review'] = self.data.review.apply(lambda x: x.replace('<br />', ''))\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        if remove_stopWords:\n",
    "            self.data['review'] = self.data.review.apply(lambda x: ' '.join([c for c in x.split() if c not in stop_words]))\n",
    "        self.data['review'] = self.data.review.apply(lambda x: ''.join([c for c in x if c not in punctuation]))\n",
    "        self.data['reviewLen'] = self.data.review.apply(lambda x: len([c for c in x.split()]))\n",
    "        self.data = self.data[self.data['reviewLen'].isin([i for i in range(self.min_len, self.max_len)])].reset_index(drop=True)    \n",
    "        if embedding=='default':\n",
    "            self.word_to_ix = {}\n",
    "            for review in self.data['review']:\n",
    "                for word in review.split():\n",
    "                    if word not in self.word_to_ix:\n",
    "                        self.word_to_ix[word] = len(self.word_to_ix)+1 #0 is for paddings\n",
    "        self.tag_to_ix = {\"1\":1, \"0\":0}\n",
    "        self.idx_list = []\n",
    "        self.lenReview_list = []\n",
    "        self.label_list = []\n",
    "        print('Generating data tensors...')\n",
    "        for i in progress_bar(range(0, self.data.shape[0])):\n",
    "            review = self.data['review'][i]\n",
    "            label = self.data['label'][i]\n",
    "            \n",
    "            idxs = [self.word_to_ix[w] for w in review.split()]\n",
    "            lenReview = self.data['reviewLen'][i]#min(len(idxs), self.max_len)\n",
    "            idxs = self.pad_data(idxs)\n",
    "            \n",
    "            review = torch.tensor(idxs, dtype=torch.long)\n",
    "            self.idx_list.append(review)\n",
    "            #label = self.tag_to_ix[label]\n",
    "            label = torch.tensor(label, dtype=torch.long)\n",
    "            self.label_list.append(label)\n",
    "            lenReview = torch.tensor(lenReview, dtype=torch.long)\n",
    "            self.lenReview_list.append(lenReview)\n",
    "            \n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def pad_data(self, s):\n",
    "        padded = np.zeros((self.max_len,),dtype=np.int64)\n",
    "        if len(s) > self.max_len: padded[:] = s[:self.max_len]\n",
    "        else: padded[:len(s)] = s\n",
    "        return padded\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.idx_list[index], self.label_list[index], self.lenReview_list[index]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelIMDB(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, target_size):\n",
    "        super(ModelIMDB, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        #self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.lstm = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.target = nn.Linear(hidden_dim, target_size)\n",
    "    \n",
    "    def forward(self, review, lengths):\n",
    "        #pdb.set_trace()\n",
    "        self.embs = self.word_embeddings(review)\n",
    "        self.embspack = pack_padded_sequence(self.embs, lengths, batch_first=True)\n",
    "        #lstm_out, self.h = self.lstm(self.embspack)\n",
    "        lstm_out, self.h = self.lstm(self.embspack)\n",
    "        \n",
    "        #outp = self.target(self.h[0]) #[hidden state, cell state]\n",
    "        outp = self.target(self.h)\n",
    "        return outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "    epoch_loss = 0\n",
    "    epoch_auc = 0\n",
    "    epoch_f1 = 0\n",
    "    model.train()\n",
    "    count = 0\n",
    "    for batch in progress_bar(iterator):\n",
    "        #pdb.set_trace()\n",
    "        optimizer.zero_grad()\n",
    "        text,labels,lengths = batch\n",
    "        lengths_Argsorted = lengths.argsort(descending=True)\n",
    "        lengths = lengths[lengths_Argsorted]\n",
    "        labels = labels[lengths_Argsorted]\n",
    "        text = text.to(device)\n",
    "        labels = labels.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        outputs = model(text, lengths).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        softmax = torch.nn.Softmax(dim=1)\n",
    "        \n",
    "        labels = labels.cpu().detach().numpy()\n",
    "        predictions = softmax(outputs).cpu().detach().numpy()\n",
    "        auc = metrics.roc_auc_score(labels, predictions[:,-1])\n",
    "        f1 = metrics.f1_score(labels, np.round(predictions[:,-1]))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_auc += auc\n",
    "        epoch_f1 += f1\n",
    "        count += 1\n",
    "    return epoch_loss/len(iterator), epoch_auc/len(iterator), epoch_f1/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "    epoch_loss = 0\n",
    "    epoch_auc = 0\n",
    "    epoch_f1 = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar(iterator):\n",
    "            #pdb.set_trace()\n",
    "            text,labels,lengths = batch\n",
    "            lengths_Argsorted = lengths.argsort(descending=True)\n",
    "            lengths = lengths[lengths_Argsorted]\n",
    "            labels = labels[lengths_Argsorted]\n",
    "            text = text.to(device)\n",
    "            labels = labels.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            outputs = model(text, lengths).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            softmax = torch.nn.Softmax(dim=1)\n",
    "            \n",
    "            labels = labels.cpu().detach().numpy()\n",
    "            predictions = softmax(outputs).cpu().detach().numpy()\n",
    "            auc = metrics.roc_auc_score(labels, predictions[:,-1])\n",
    "            f1 = metrics.f1_score(labels, np.round(predictions[:,-1]))\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_auc += auc\n",
    "            epoch_f1 += f1\n",
    "    return epoch_loss/len(iterator), epoch_auc/len(iterator), epoch_f1/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "test_split = 0.1\n",
    "shuffle_data = True\n",
    "rand_seed = 100\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data tensors...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='46561' class='' max='46561', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [46561/46561 00:04<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = IMDBDatasetv2('IMDB_Dataset_v2.csv', device=device, remove_stopWords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split_val = int(np.floor(test_split*dataset_size))\n",
    "if shuffle_data:\n",
    "    np.random.seed(rand_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices, valid_indices = np.array(indices[2*split_val:]),np.array(indices[:split_val]),np.array(indices[split_val:2*split_val])\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "train_loader = DataLoader(dataset, batch_size = batch_size, sampler = train_sampler, num_workers = 8, drop_last=True)\n",
    "test_loader = DataLoader(dataset, batch_size = batch_size, sampler = test_sampler, num_workers = 8, drop_last=True)\n",
    "valid_loader = DataLoader(dataset, batch_size = batch_size, sampler = valid_sampler, num_workers = 8, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37249"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices[2*split_val:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelIMDB(100, 50, len(dataset.word_to_ix)+1, len(dataset.tag_to_ix)).to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelIMDB(\n",
       "  (word_embeddings): Embedding(220395, 100, padding_idx=0)\n",
       "  (lstm): GRU(100, 50, batch_first=True)\n",
       "  (target): Linear(in_features=50, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='291' class='' max='291', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [291/291 00:09<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='36' class='' max='36', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [36/36 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6959861176939764\n",
      "Best Validation Loss: 0.694, AUC: 0.50, F1:0.39 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='291' class='' max='291', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [291/291 00:09<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='36' class='' max='36', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [36/36 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6942852110797187\n",
      "Best Validation Loss: 0.693, AUC: 0.51, F1:0.36 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='291' class='' max='291', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [291/291 00:09<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='36' class='' max='36', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [36/36 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6934085893876774\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='291', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-220-22a672cf4c15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_valid_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-212-29240423d2af>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/s/jawar/h/nobackup/fahad/miniconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/s/jawar/h/nobackup/fahad/miniconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 15\n",
    "best_valid_loss = np.inf\n",
    "best_valid_auc = 0\n",
    "best_valid_f1 = 0\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_auc, train_f1 = train(model, train_loader, optimizer, criterion, device)\n",
    "    valid_loss, valid_auc, valid_f1 = evaluate(model, valid_loader, criterion, device)\n",
    "    print(train_loss)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        best_valid_auc = valid_auc\n",
    "        best_valid_f1 = valid_f1\n",
    "        print(\"Best Validation Loss: %.3f, AUC: %.2f, F1:%.2f\"%(best_valid_loss, best_valid_auc, best_valid_f1), \"\\n\")\n",
    "        torch.save({'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict':optimizer.state_dict(),\n",
    "                    'loss':valid_loss\n",
    "                    },\n",
    "                   'saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
